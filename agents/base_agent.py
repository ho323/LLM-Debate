from abc import ABC, abstractmethod
from typing import List, Dict, Optional
import os
import subprocess
import tempfile

# transformersëŠ” ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©
try:
    from transformers import AutoTokenizer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("âš ï¸ transformers ì—†ìŒ - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")

class BaseAgent(ABC):
    def __init__(self, model_path: str = 'C:/Users/User/Documents/EXAONE-4.0-32B-Q4_K_M.gguf'):
        self.model_path = model_path
        self.tokenizer = None
        self.llama_cli_path = "C:/Users/User/LLM-Debate/llama.cpp/build/bin/Release/llama-cli.exe"
        print(f"ğŸ”§ BaseAgent ì´ˆê¸°í™” - 32B ëª¨ë¸ ìµœì í™” ë²„ì „")
        print(f"â° ì‘ë‹µ ìƒì„± ì‹œê°„: ë¬´ì œí•œ (ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°)")
        self._load_model()
    
    def _load_model(self):
        """í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ê³  ëª¨ë¸ ê²½ë¡œë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        print(f"EXAONE ëª¨ë¸ ì„¤ì • ì¤‘: {self.model_path}")
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ (ì„ íƒì )
        if TRANSFORMERS_AVAILABLE:
            try:
                self.tokenizer = AutoTokenizer.from_pretrained("LGAI-EXAONE/EXAONE-4.0-32B")
                print("âœ… EXAONE í† í¬ë‚˜ì´ì € ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {e} - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
                self.tokenizer = None
        
        print("EXAONE ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
    
    def generate_response(self, prompt: str, max_length: int = 1000, target_length: str = "ê°„ê²°í•˜ê²Œ") -> str:
        """í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print(f"ğŸ”„ 32B ëª¨ë¸ ì‘ë‹µ ìƒì„± ì‹œì‘... (ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°)")
        
        try:
            # ì˜¤ë¥˜ ë°©ì§€ìš© í…œí”Œë¦¿
            if self.tokenizer:
                try:
                    messages = [{"role": "user", "content": prompt}]
                    input_text = self.tokenizer.apply_chat_template(
                        messages,
                        tokenize=False,
                        add_generation_prompt=True,
                    )
                except Exception as e:
                    print(f"âš ï¸ í† í¬ë‚˜ì´ì € í…œí”Œë¦¿ ì˜¤ë¥˜: {e} - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
                    input_text = f"User: {prompt}\nAssistant:"
            else:
                # ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
                input_text = f"User: {prompt}\nAssistant:"
            
            # ì„ì‹œ íŒŒì¼ì— ì…ë ¥ ì €ì¥ (UTF-8 ì¸ì½”ë”© ëª…ì‹œ)
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
                f.write(input_text)
                input_file = f.name
            
            try:
                # 32B ëª¨ë¸ìš© ìµœì í™”ëœ llama-cli ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ì—†ìŒ)
                result = subprocess.run(
                    [
                        self.llama_cli_path,
                        "-m", self.model_path,
                        "-f", input_file,
                        "-n", str(max_length),  # í† í° ìˆ˜ ì ë‹¹íˆ ì œí•œ
                        "-c", "2048",                     # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì„¤ì •
                        "--temp", "0.7",
                        "--top-p", "0.9",
                        "--repeat-penalty", "1.1",
                        "-no-cnv",
                        "--seed", "42",
                        "-t", "4"                         # CPU ìŠ¤ë ˆë“œ ìˆ˜ ì§€ì •
                    ],
                    capture_output=True,
                    text=True,
                    # timeout ì œê±° - ë¬´ì œí•œ ëŒ€ê¸°
                    encoding='utf-8',     # UTF-8 ì¸ì½”ë”© ëª…ì‹œ
                    errors='ignore',      # ì¸ì½”ë”© ì˜¤ë¥˜ ë¬´ì‹œ
                    # Windowsì—ì„œ ì°½ ìˆ¨ê¸°ê¸° ë° ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€
                    creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
                )
                
                if result.returncode != 0:
                    error_msg = "ì‹¤í–‰ ì˜¤ë¥˜"
                    if result.stderr:
                        try:
                            error_msg = result.stderr[:100]  # ì˜¤ë¥˜ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
                        except:
                            error_msg = "ì¸ì½”ë”© ì˜¤ë¥˜ë¡œ ì½ì„ ìˆ˜ ì—†ìŒ"
                    
                    print(f"llama-cli ì‹¤í–‰ ì˜¤ë¥˜: {error_msg}")
                    return "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                # ì‘ë‹µ ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ)
                output = ""
                if result.stdout:
                    try:
                        output = result.stdout.strip()
                        print(f"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(output)}ì")
                    except Exception as e:
                        print(f"âš ï¸ ì¶œë ¥ ì½ê¸° ì˜¤ë¥˜: {e}")
                        return "ì¶œë ¥ ì½ê¸° ì‹¤íŒ¨"
                
                if output:
                    return self._extract_after_think(output)
                else:
                    return "ë¹ˆ ì‘ë‹µì´ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤."
                
            except Exception as e:
                print(f"subprocess ì˜¤ë¥˜: {e}")
                return "ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    if os.path.exists(input_file):
                        os.unlink(input_file)
                except:
                    pass  # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ê³„ì†
            
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _extract_after_think(self, output: str) -> str:
        """'</think>' ì´í›„ì˜ ë¬¸ìì—´ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤. íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì›ë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not output:
            return "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            lower_out = output.lower()
            marker = "</think>"
            idx = lower_out.rfind(marker)
            if idx != -1:
                result = output[idx + len(marker):].strip()
            else:
                result = output.strip()
            
            # [end of text] í† í° ì œê±°
            result = result.replace("[end of text]", "").replace("[END OF TEXT]", "").strip()
            
        
            if "User:" in result:
                result = result.split("User:")[0].strip()
            
            return result if result else "ì •ë¦¬ëœ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"âš ï¸ ì‘ë‹µ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return "ì‘ë‹µ ì¶”ì¶œ ì‹¤íŒ¨"
    
    def _clean_response(self, response: str) -> str:
        """ì‘ë‹µì„ ì •ë¦¬í•©ë‹ˆë‹¤ (ë°˜ë³µ ì œê±°, ë¶ˆì™„ì „ ë¬¸ì¥ ì²˜ë¦¬)."""
        if not response:
            return "ì‘ë‹µì„ ì •ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # ì¤‘ë³µ ë¬¸ì¥ ì œê±°
            sentences = response.split('.')
            unique_sentences = []
            seen = set()
            
            for sentence in sentences:
                sentence = sentence.strip()
                if sentence and sentence not in seen and len(sentence) > 10:
                    seen.add(sentence)
                    unique_sentences.append(sentence)
            
            # ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ë¶ˆì™„ì „í•˜ë©´ ì œê±°
            if unique_sentences and len(unique_sentences[-1]) < 20:
                unique_sentences = unique_sentences[:-1]
            
            result = '. '.join(unique_sentences) + ('.' if unique_sentences else '')
            return result if result else "ì •ë¦¬ëœ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"âš ï¸ ì‘ë‹µ ì •ë¦¬ ì˜¤ë¥˜: {e}")
            return response  
    
    @abstractmethod
    def process_input(self, input_data: Dict) -> str:
        """ê° ì—ì´ì „íŠ¸ë³„ ì…ë ¥ ì²˜ë¦¬ ë¡œì§"""
        pass